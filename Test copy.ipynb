{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "from imutils.object_detection import non_max_suppression\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_coco_annotations(json_path, img_dir):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        coco_data = json.load(f)\n",
    "    \n",
    "    images = {img[\"id\"]: img[\"file_name\"] for img in coco_data[\"images\"]}\n",
    "    annotations = coco_data[\"annotations\"] \n",
    "    \n",
    "    data = []\n",
    "    for ann in annotations:\n",
    "        image_id = ann[\"image_id\"]\n",
    "        image_path = os.path.join(img_dir, images[image_id])\n",
    "        category_id = ann[\"category_id\"]  # Gi·∫£ s·ª≠ ƒë√¢y l√† nh√£n cho ng∆∞·ªùi\n",
    "        bbox = ann[\"bbox\"]  # [x, y, width, height]\n",
    "\n",
    "        # ƒê·ªçc ·∫£nh v√† c·∫Øt v√πng bounding box c·ªßa ng∆∞·ªùi\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            continue  # B·ªè qua ·∫£nh l·ªói\n",
    "\n",
    "        x, y, w, h = map(int, bbox)\n",
    "        cropped_img = img[y:y+h, x:x+w]\n",
    "        cropped_img = cv2.resize(cropped_img, (64, 128))\n",
    "\n",
    "        # Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng HOG cho v√πng ng∆∞·ªùi\n",
    "        features = hog(cropped_img, pixels_per_cell=(4, 4), cells_per_block=(2, 2))\n",
    "        \n",
    "        data.append({\n",
    "            \"image_path\": image_path,\n",
    "            \"features\": features,\n",
    "            \"label\": category_id  # Nh√£n ng∆∞·ªùi (v√≠ d·ª•: 1)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def extract_negative_samples(json_path, img_dir, num_samples=10):\n",
    "    \"\"\"\n",
    "    Tr√≠ch xu·∫•t c√°c m·∫´u √¢m t·ª´ c√°c v√πng kh√¥ng ch·ª©a bounding box c·ªßa ng∆∞·ªùi.\n",
    "    num_samples: s·ªë l∆∞·ª£ng m·∫´u √¢m c·∫ßn l·∫•y cho m·ªói ·∫£nh.\n",
    "    \"\"\"\n",
    "    with open(json_path, \"r\") as f:\n",
    "        coco_data = json.load(f)\n",
    "    \n",
    "    images = {img[\"id\"]: img[\"file_name\"] for img in coco_data[\"images\"]}\n",
    "    # T·∫≠p h·ª£p t·∫•t c·∫£ c√°c bounding box c·ªßa ng∆∞·ªùi cho m·ªói ·∫£nh\n",
    "    bbox_dict = {}\n",
    "    for ann in coco_data[\"annotations\"]:\n",
    "        image_id = ann[\"image_id\"]\n",
    "        bbox = ann[\"bbox\"]  # [x, y, width, height]\n",
    "        if image_id not in bbox_dict:\n",
    "            bbox_dict[image_id] = []\n",
    "        bbox_dict[image_id].append(list(map(int, bbox)))\n",
    "    \n",
    "    negative_data = []\n",
    "    for image_id, file_name in images.items():\n",
    "        image_path = os.path.join(img_dir, file_name)\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            continue\n",
    "        img_h, img_w = img.shape\n",
    "        \n",
    "        # L·∫•y c√°c bounding box c·ªßa ng∆∞·ªùi (n·∫øu c√≥)\n",
    "        person_bboxes = bbox_dict.get(image_id, [])\n",
    "        \n",
    "        # Sinh ng·∫´u nhi√™n c√°c v√πng m·∫´u √¢m\n",
    "        samples = 0\n",
    "        attempts = 0\n",
    "        while samples < num_samples and attempts < num_samples * 10:\n",
    "            # Sinh t·ªça ƒë·ªô ng·∫´u nhi√™n\n",
    "            w, h = 64, 128\n",
    "            x = np.random.randint(0, img_w - w)\n",
    "            y = np.random.randint(0, img_h - h)\n",
    "            candidate_box = [x, y, x+w, y+h]  # [x1, y1, x2, y2]\n",
    "            \n",
    "            # Ki·ªÉm tra giao nhau v·ªõi c√°c bounding box c·ªßa ng∆∞·ªùi\n",
    "            overlap = False\n",
    "            for bbox in person_bboxes:\n",
    "                # bbox g·ªëc ·ªü d·∫°ng [x, y, width, height] chuy·ªÉn th√†nh [x1, y1, x2, y2]\n",
    "                pb = [bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]]\n",
    "                # T√≠nh giao nhau\n",
    "                ix1 = max(candidate_box[0], pb[0])\n",
    "                iy1 = max(candidate_box[1], pb[1])\n",
    "                ix2 = min(candidate_box[2], pb[2])\n",
    "                iy2 = min(candidate_box[3], pb[3])\n",
    "                iw = max(0, ix2 - ix1)\n",
    "                ih = max(0, iy2 - iy1)\n",
    "                if iw * ih > 0:  # N·∫øu c√≥ giao nhau\n",
    "                    overlap = True\n",
    "                    break\n",
    "            if not overlap:\n",
    "                cropped_img = img[y:y+h, x:x+w]\n",
    "                # N·∫øu k√≠ch th∆∞·ªõc kh√¥ng ƒë·ªß th√¨ b·ªè qua\n",
    "                if cropped_img.shape[0] != h or cropped_img.shape[1] != w:\n",
    "                    attempts += 1\n",
    "                    continue\n",
    "                cropped_img = cv2.resize(cropped_img, (64, 128))\n",
    "                features = hog(cropped_img, pixels_per_cell=(4, 4), cells_per_block=(2, 2))\n",
    "                negative_data.append({\n",
    "                    \"image_path\": image_path,\n",
    "                    \"features\": features,\n",
    "                    \"label\": 0  # Nh√£n cho non-person\n",
    "                })\n",
    "                samples += 1\n",
    "            attempts += 1\n",
    "    return pd.DataFrame(negative_data)\n",
    "\n",
    "# V√≠ d·ª•: Load t·∫≠p train & test cho m·∫´u ng∆∞·ªùi v√† m·∫´u non-person\n",
    "train_person_df = load_coco_annotations(\"train/_annotations.coco.json\", \"train/\")\n",
    "train_negative_df = extract_negative_samples(\"train/_annotations.coco.json\", \"train/\", num_samples=5)\n",
    "\n",
    "test_person_df = load_coco_annotations(\"test/_annotations.coco.json\", \"test/\")\n",
    "test_negative_df = extract_negative_samples(\"test/_annotations.coco.json\", \"test/\", num_samples=5)\n",
    "\n",
    "# K·∫øt h·ª£p d·ªØ li·ªáu\n",
    "train_df = pd.concat([train_person_df, train_negative_df]).reset_index(drop=True)\n",
    "test_df = pd.concat([test_person_df, test_negative_df]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Accuracy: 0.9877\n"
     ]
    }
   ],
   "source": [
    "# Chu·∫©n b·ªã d·ªØ li·ªáu\n",
    "X_train = np.array(train_df[\"features\"].tolist(), dtype=np.float32)\n",
    "y_train = train_df[\"label\"].values\n",
    "X_test = np.array(test_df[\"features\"].tolist(), dtype=np.float32)\n",
    "y_test = test_df[\"label\"].values\n",
    "\n",
    "# Chu·∫©n h√≥a d·ªØ li·ªáu\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train).astype(np.float32)  # Chuy·ªÉn v·ªÅ float32\n",
    "X_test_scaled = scaler.transform(X_test).astype(np.float32)  # Chuy·ªÉn v·ªÅ float32\n",
    "\n",
    "# L∆∞u scaler\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "# Hu·∫•n luy·ªán Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=20, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "y_pred = rf.predict(X_test_scaled)\n",
    "\n",
    "# T√≠nh Accuracy\n",
    "accuracy = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "print(f\"üéØ Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9876543209876543\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ M√¥ h√¨nh Random Forest ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán!\n"
     ]
    }
   ],
   "source": [
    "# L∆∞u m√¥ h√¨nh\n",
    "joblib.dump(rf, \"random_forest_model.pkl\")\n",
    "print(\"‚úÖ M√¥ h√¨nh Random Forest ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32907, 16740)\n",
      "(3321, 16740)\n",
      "(32907,)\n",
      "(3321,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H√†m ph√°t hi·ªán ng∆∞·ªùi v·ªõi Sliding Window & HOG\n",
    "def detect_people(image_path, model, scaler):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        print(f\"L·ªói: Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh {image_path}\")\n",
    "        return []\n",
    "    \n",
    "    h, w = img.shape\n",
    "    window_size = (64, 128)\n",
    "    step_size = 16\n",
    "    detections = []\n",
    "    \n",
    "    for y in range(0, h - window_size[1], step_size):\n",
    "        for x in range(0, w - window_size[0], step_size):\n",
    "            window = img[y:y+window_size[1], x:x+window_size[0]]\n",
    "            features = hog(window, pixels_per_cell=(4, 4), cells_per_block=(2, 2))\n",
    "            features_scaled = scaler.transform([features])\n",
    "            pred = model.predict(features_scaled)\n",
    "            if pred == 1:\n",
    "                detections.append((x, y, x+window_size[0], y+window_size[1]))\n",
    "    \n",
    "    # Lo·∫°i b·ªè v√πng tr√πng l·∫∑p b·∫±ng Non-Maximum Suppression (NMS)\n",
    "    detections = np.array(detections)\n",
    "    if len(detections) > 0:\n",
    "        picks = non_max_suppression(detections, probs=None, overlapThresh=0.3)\n",
    "        return picks.tolist()\n",
    "    return []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             image_path  \\\n",
      "0     test/11516_jpg.rf.7cf4e332eafdb31672c0025195b6...   \n",
      "1     test/11516_jpg.rf.7cf4e332eafdb31672c0025195b6...   \n",
      "2     test/12545_jpg.rf.69333f3b7d11b9cce33062b0cacf...   \n",
      "3     test/6552_jpg.rf.ad79089b0fb56be23f73253fc5c0a...   \n",
      "4     test/6552_jpg.rf.ad79089b0fb56be23f73253fc5c0a...   \n",
      "...                                                 ...   \n",
      "3316  test/2295_jpg.rf.a7f90255600bae464023779db2cd5...   \n",
      "3317  test/2295_jpg.rf.a7f90255600bae464023779db2cd5...   \n",
      "3318  test/2295_jpg.rf.a7f90255600bae464023779db2cd5...   \n",
      "3319  test/2295_jpg.rf.a7f90255600bae464023779db2cd5...   \n",
      "3320  test/2295_jpg.rf.a7f90255600bae464023779db2cd5...   \n",
      "\n",
      "                                               features  label  \n",
      "0     [0.2640417780831969, 0.2640417780831969, 0.0, ...      1  \n",
      "1     [0.29242355241801, 0.0, 0.0, 0.0, 0.1561207866...      1  \n",
      "2     [0.08204885055352479, 0.0, 0.17405188797561302...      1  \n",
      "3     [0.4397735461528512, 0.0, 0.0, 0.0, 0.0, 0.0, ...      1  \n",
      "4     [0.2543070370464943, 0.0, 0.0, 0.0, 0.0, 0.0, ...      1  \n",
      "...                                                 ...    ...  \n",
      "3316  [0.07315523891068428, 0.0, 0.0, 0.098488253239...      0  \n",
      "3317  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      0  \n",
      "3318  [0.06262785546604664, 0.0, 0.1476152709329882,...      0  \n",
      "3319  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      0  \n",
      "3320  [0.20050683603864364, 0.0967254036204798, 0.11...      0  \n",
      "\n",
      "[3321 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\11516_jpg.rf.7cf4e332eafdb31672c0025195b6c445.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\12545_jpg.rf.69333f3b7d11b9cce33062b0cacfd523.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\6552_jpg.rf.ad79089b0fb56be23f73253fc5c0a921.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\13876_jpg.rf.430b135cb2913a6d1672ab657b952b1f.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\5414_jpg.rf.b212d2891d8ba3d586fd3dd2884568c1.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\8008_jpg.rf.4a6020858202d28a1444b6cd222183f5.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\2311_jpg.rf.b7409c0ef73d2082c68e291f8433913f.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\13489_jpg.rf.c8cbd2afc7201a20e4ee39bea97ffdc6.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\13116_jpg.rf.cf2f2d6c4477e608a578399a74c4a528.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\5516_jpg.rf.4f3152a305fe00760291bb221a00fb7e.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\9007_jpg.rf.7f574479ef4706adb3601992cf48b7d0.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\11449_jpg.rf.ab35b7bedca12232dc1658be81fd4616.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\6587_jpg.rf.389aee3ce0a6a0793148a223a9400227.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\13461_jpg.rf.1cfba59fb8f5b2c8a1b81d501088cb07.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\9623_jpg.rf.282f2f9a2b519f7d602d8044e7c0ae06.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\13406_jpg.rf.3e67f34cfbf4f9d07382bc4b916154bb.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\16124_jpg.rf.748cd3a0a8447d0c8eab973cfc05eaaf.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\12876_jpg.rf.471161d8b3104a9a9828ef216ce12b50.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\13904_jpg.rf.4c1317e2d3ce8bdab951a1ecf16c7a99.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\15183_jpg.rf.3ceee9c1abec346efdde15d11d32c3a8.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\5395_jpg.rf.6b2da6118f8fd4792f3e21135dc1f8b2.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\12494_jpg.rf.642c7c2a850c70ef1930df4bbe45d5e5.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\6569_jpg.rf.0f080e038aa5ad87b8e4455ab4f56d45.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\15093_jpg.rf.73a15ff6dfadbd2c16464eccda5a49ec.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\11903_jpg.rf.ab7a2f5f7f5529ea4b46121d983a779a.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\14951_jpg.rf.d06818f89a01b40fb6498a42e66c856b.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\13140_jpg.rf.6ea4a2b8b1b193e9819e7f05d11e0bbf.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\1719_jpg.rf.34012f676710ee05ea73fd090c47e386.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\5903_jpg.rf.659b4092be473d9d4e14b388e62c0cf9.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\9608_jpg.rf.4c9ab4b0a8c8c7b656bb65f9add0d3cb.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\13160_jpg.rf.f901c9e1135acfab4554a236a0015b51.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\13697_jpg.rf.405fe91d0eb7d02975208c70eefc1503.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\924_jpg.rf.26231f33f9a5b0c020faed76e4425373.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\11990_jpg.rf.b004c2d72b3c131b5d201905d777da78.jpg\n",
      "‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: output\\13669_jpg.rf.1e2bdf0bb805d9264b9a810913b6cc91.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m unique_test_df.iterrows():\n\u001b[32m     13\u001b[39m     image_path = row[\u001b[33m\"\u001b[39m\u001b[33mimage_path\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     detected_boxes = \u001b[43mdetect_people\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrf_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     img = cv2.imread(image_path)\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mdetect_people\u001b[39m\u001b[34m(image_path, model, scaler)\u001b[39m\n\u001b[32m     15\u001b[39m window = img[y:y+window_size[\u001b[32m1\u001b[39m], x:x+window_size[\u001b[32m0\u001b[39m]]\n\u001b[32m     16\u001b[39m features = hog(window, pixels_per_cell=(\u001b[32m4\u001b[39m, \u001b[32m4\u001b[39m), cells_per_block=(\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m features_scaled = \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m pred = model.predict(features_scaled)\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pred == \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project\\.venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m         return_tuple = (\n\u001b[32m    323\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    324\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    325\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1062\u001b[39m, in \u001b[36mStandardScaler.transform\u001b[39m\u001b[34m(self, X, copy)\u001b[39m\n\u001b[32m   1059\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m   1061\u001b[39m copy = copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.copy\n\u001b[32m-> \u001b[39m\u001b[32m1062\u001b[39m X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1063\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1064\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1066\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1067\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1068\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1069\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1071\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1073\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sparse.issparse(X):\n\u001b[32m   1074\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.with_mean:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2944\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2942\u001b[39m         out = X, y\n\u001b[32m   2943\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2944\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2945\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2946\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1107\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1102\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m expected <= 2.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1103\u001b[39m         % (array.ndim, estimator_name)\n\u001b[32m   1104\u001b[39m     )\n\u001b[32m   1106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1107\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1115\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1116\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:116\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;66;03m# First try an O(n) time, O(1) space solution for the common case that\u001b[39;00m\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# everything is finite; fall back to O(n) space `np.isinf/isnan` or custom\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[38;5;66;03m# Cython implementation to prevent false positives and provide a detailed\u001b[39;00m\n\u001b[32m    114\u001b[39m \u001b[38;5;66;03m# error message.\u001b[39;00m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m np.errstate(over=\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     first_pass_isfinite = xp.isfinite(\u001b[43mxp\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project\\.venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:2466\u001b[39m, in \u001b[36msum\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, initial, where)\u001b[39m\n\u001b[32m   2463\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[32m   2464\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[32m-> \u001b[39m\u001b[32m2466\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2467\u001b[39m \u001b[43m    \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msum\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2468\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere\u001b[49m\n\u001b[32m   2469\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project\\.venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:86\u001b[39m, in \u001b[36m_wrapreduction\u001b[39m\u001b[34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[39m\n\u001b[32m     83\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     84\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis=axis, out=out, **passkwargs)\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Load m√¥ h√¨nh\n",
    "rf_model = joblib.load(\"random_forest_model.pkl\")\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "\n",
    "# Th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£\n",
    "output_folder = \"output\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "unique_test_df = test_df.drop_duplicates(subset=[\"image_path\"])\n",
    "\n",
    "# Duy·ªát qua t·∫≠p test\n",
    "for index, row in unique_test_df.iterrows():\n",
    "    image_path = row[\"image_path\"]\n",
    "    detected_boxes = detect_people(image_path, rf_model, scaler)\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is not None:\n",
    "        for (x1, y1, x2, y2) in detected_boxes:\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        output_path = os.path.join(output_folder, os.path.basename(image_path))\n",
    "        cv2.imwrite(output_path, img)\n",
    "        print(f\"‚úÖ ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£: {output_path}\")\n",
    "    else:\n",
    "        print(f\"‚ùå L·ªói khi ƒë·ªçc ·∫£nh: {image_path}\")\n",
    "\n",
    "print(\"üéØ Ho√†n th√†nh nh·∫≠n di·ªán tr√™n t·∫≠p test!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
